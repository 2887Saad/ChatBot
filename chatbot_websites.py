# -*- coding: utf-8 -*-
"""Chatbot_websites.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_1HeD1mK_wXfjgvY4VGNFKSQBE5Imeh
"""

!pip install langchain
!pip install faiss-cpu
!pip install openai

import os
os.environ["OPENAI_API_KEY"] = ""

urls = [
    'https://www.mosaicml.com/blog/mpt-7b',
    'https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models',
    'https://lmsys.org/blog/2023-03-30-vicuna/'
]

from langchain.document_loaders import UnstructuredURLLoader
loaders = UnstructuredURLLoader(urls=urls)
data = loaders.load()

!pip install unstructured

data

# Text Splitter
from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(separator='\n',
                                      chunk_size=1000,
                                      chunk_overlap=200)


docs = text_splitter.split_documents(data)

docs

len(docs)

import pickle
import faiss
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

embeddings

#!pip install tiktoken
vectorStore_openAI = FAISS.from_documents(docs, embeddings)
vectorStore_openAI
#with open("/content/faiss_store_openai.pkl", "wb") as f:
 #    pickle.dump(vectorStore_openAI, f)

with open("/content/faiss_store_openai.pkl", "rb") as f:
    VectorStore = pickle.load(f)

VectorStore

from langchain.chains.conversation.memory import ConversationSummaryMemory
from langchain.chains import ConversationChain
from langchain.chains.question_answering import load_qa_chain
from langchain import OpenAI

llm=OpenAI(temperature=0, model_name='gpt-3.5-turbo-instruct')

llm

memory = ConversationSummaryMemory(llm=OpenAI())
chain = ConversationChain(llm=llm, verbose=True,memory=memory)

chain({"input": "How big is stableLM?"}, return_only_outputs=True)

chain({"input": "How good is Vicuna?"}, return_only_outputs=True)

chain({"input": "Which MPT-7B model is the bast one?"}, return_only_outputs=True)


#for sl lite data as database
from langchain_community.utilities import SQLDatabase
from langchain_experimental.sql import SQLDatabaseChain
from langchain_openai import OpenAI

db = SQLDatabase.from_uri("")
llm = OpenAI(temperature=0, verbose=True)
db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)

